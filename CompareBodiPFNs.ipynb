{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89768a0e",
   "metadata": {},
   "source": [
    "# PFN Comparison\n",
    "\n",
    "In this file, we compare the performance of different BODi-trained PFNs. First, we compare the regression performance, then at overlap scores, then at BO performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72510972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/timothyshinners/Library/Python/3.9/lib/python/site-packages')\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import mcbo\n",
    "\n",
    "from mcbo import task_factory\n",
    "from mcbo.optimizers.bo_builder import BoBuilder, BO_ALGOS\n",
    "from mcbo.optimizers.non_bo.random_search import RandomSearch\n",
    "from mcbo.optimizers.non_bo.local_search import LocalSearch\n",
    "from mcbo.acq_funcs import acq_factory\n",
    "\n",
    "import pfns4bo\n",
    "from pfns4bo.pfn_bo_bayesmark import PFNOptimizer\n",
    "from pfns4mvbo.priors import cocabo_prior\n",
    "from pfns4mvbo.pfn_plotting import showPFNPosteriorDistributions, showPFNvsCOCABOPosteriorDistributions, showPFNvsCOCABO\n",
    "from pfns4mvbo.mvpfn_optimizer import MVPFNOptimizer\n",
    "from pfns4mvbo.pfn_acq_func import PFNAcqFunc\n",
    "from pfns4mvbo.pfn_model import PFNModel\n",
    "from pfns4mvbo.evaluation import do_regression_evaluation, compare_pfn_vs_mcbo, do_validation_experiment\n",
    "import re\n",
    "\n",
    "\n",
    "def bootstrap_ub(col):\n",
    "    # returns the lower and upper bounds of the 95% confidence interval\n",
    "    bootstrap_samples = np.random.choice(col, size=[1000, len(col)], replace=True).mean(axis=1)\n",
    "    assert bootstrap_samples.shape[0] == 1000\n",
    "    ub = np.quantile(bootstrap_samples, 0.975)\n",
    "    return ub\n",
    "\n",
    "def bootstrap_lb(col):\n",
    "    # returns the lower and upper bounds of the 95% confidence interval\n",
    "    bootstrap_samples = np.random.choice(col, size=[1000, len(col)], replace=True).mean(axis=1)\n",
    "    lb = np.quantile(bootstrap_samples, 0.025)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61274ca6-65e4-4681-9b99-2b3c062b912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3642e5-be01-44c1-927b-c82db8794e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFN_LIST = ['6', '24']\n",
    "#for i in range(34,39):\n",
    "#    PFN_LIST += [str(i)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b906e-717e-4ae7-9822-52ef66f85346",
   "metadata": {},
   "source": [
    "# INFO and training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753903c-bbd9-4bd1-b8b8-423041024ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pfn_no in PFN_LIST:\n",
    "    try:\n",
    "        pfn = torch.load(f'trained_models/pfn_bodi_{pfn_no}.pth')\n",
    "        print(pfn_no, pfn.info)\n",
    "        loss_curve = pfn.info['loss_curve']\n",
    "        print(pfn_no, pfn.info.get('learning_rate', None), pfn.info.get('bptt', None))\n",
    "        plt.plot(np.linspace(0, 1, len(loss_curve)), loss_curve, label=pfn_no)\n",
    "    except:\n",
    "        print(f'PFN {pfn_no} has no loss curve')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623d875-8bc5-4657-8984-0d08a0a4350e",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "We assess the regression performance of our trained PFN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09730e-8377-427c-ad9f-d19e4088d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'nll_normed'\n",
    "\n",
    "regression_df_list = []\n",
    "\n",
    "for i, pfn_no in enumerate(PFN_LIST):\n",
    "    regression_df_list += [pd.read_csv('bodi_evaluation_data/regression_results_'+pfn_no+'.csv')]\n",
    "    regression_df_list[i] = regression_df_list[i][regression_df_list[i]['model_name'] == 'PFN']\n",
    "    regression_df_list[i]['PFN_number'] = pfn_no\n",
    "\n",
    "cocabo_baseline = pd.read_csv('evaluation_data/regression_results_casmo.csv')\n",
    "cocabo_baseline = cocabo_baseline[cocabo_baseline['model_name'] != 'PFN']\n",
    "cocabo_baseline['PFN_number'] = 'Casmopolitan'\n",
    "cocabo_baseline = cocabo_baseline.reset_index(drop=True)\n",
    "\n",
    "assert 1==0, 'switch cocabo to bodi'\n",
    "\n",
    "regression_df_list += [cocabo_baseline]\n",
    "\n",
    "# check the seed is consistent across data frames\n",
    "seed = regression_df_list[0]['seed'][0]\n",
    "for df in regression_df_list:\n",
    "    assert df['seed'][0] == seed\n",
    "\n",
    "if 'Casmopolitan' not in PFN_LIST:\n",
    "    PFN_LIST += ['Casmopolitan']\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 12))\n",
    "ax[0,0].set_title('Loss vs Amount of Training Data, PFN')\n",
    "ax[0,0].set_xlabel('Number of Training Points')\n",
    "ax[0,0].set_ylabel('Loss')\n",
    "ax[1,0].set_title('Loss vs Number of Dimensions, PFN')\n",
    "ax[1,0].set_xlabel('Number of Dimensions')\n",
    "ax[1,0].set_ylabel('Loss')\n",
    "ax[2,0].set_title('Histogram of Losses, PFN')\n",
    "ax[2,0].set_xlabel('Loss')\n",
    "ax[0,1].set_title('Ranks')\n",
    "ax[0,1].set_xlabel('Number of Training Points')\n",
    "ax[0,1].set_ylabel('Rank')\n",
    "ax[1,1].set_title('Ranks')\n",
    "ax[1,1].set_xlabel('Number of Dimensions')\n",
    "ax[1,1].set_ylabel('Rank')\n",
    "ax[2,1].set_title('Best PFN')\n",
    "ax[2,1].set_xlabel('Number of Training Points')\n",
    "ax[2,1].set_ylabel('Number of Dimensions')\n",
    "\n",
    "for i, regression_df in enumerate(regression_df_list):\n",
    "    mean = regression_df.groupby('n_training_data')[loss].mean()\n",
    "    median = regression_df.groupby('n_training_data')[loss].median()\n",
    "    ub = regression_df.groupby('n_training_data')[loss].apply(bootstrap_ub)\n",
    "    lb = regression_df.groupby('n_training_data')[loss].apply(bootstrap_lb)\n",
    "    ax[0,0].plot(mean, label = PFN_LIST[i])\n",
    "    ax[0,0].fill_between(mean.index.get_level_values('n_training_data'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    regression_df['n_dims'] = regression_df['num_dims'] + regression_df['cat_dims']\n",
    "    mean = regression_df.groupby('n_dims')[loss].mean()\n",
    "    median = regression_df.groupby('n_dims')[loss].median()\n",
    "    ub = regression_df.groupby('n_dims')[loss].apply(bootstrap_ub)\n",
    "    lb = regression_df.groupby('n_dims')[loss].apply(bootstrap_lb)\n",
    "    ax[1,0].plot(mean, label = PFN_LIST[i])\n",
    "    ax[1,0].fill_between(mean.index.get_level_values('n_dims'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    ax[2,0].hist(regression_df[loss], alpha=0.3, bins=100, label = PFN_LIST[i])\n",
    "\n",
    "# now we make ranking plot, using the raw loss calculations\n",
    "regression_df = regression_df_list[0]\n",
    "losses = np.array([df[loss[0:3]+'_raw'] for df in regression_df_list]).T\n",
    "ranks = np.argsort(losses, axis=1)\n",
    "ranks = np.argsort(ranks)\n",
    "\n",
    "avg_ranks = np.zeros(len(PFN_LIST))\n",
    "proportion_wins = np.zeros(len(PFN_LIST))\n",
    "\n",
    "for i in range(ranks.shape[1]):\n",
    "    regression_df[PFN_LIST[i]+'_rank'] = ranks[:, i]\n",
    "    avg_ranks[i] = regression_df[PFN_LIST[i]+'_rank'].mean()\n",
    "    proportion_wins[i] = (regression_df[PFN_LIST[i]+'_rank'] == 0).mean()\n",
    "    mean = regression_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].mean()\n",
    "    ub = regression_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].apply(bootstrap_ub)\n",
    "    lb = regression_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].apply(bootstrap_lb)\n",
    "    ax[0,1].plot(mean, label = PFN_LIST[i])\n",
    "    ax[0,1].fill_between(mean.index.get_level_values('n_training_data'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    mean = regression_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].mean()\n",
    "    ub = regression_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].apply(bootstrap_ub)\n",
    "    lb = regression_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].apply(bootstrap_lb)\n",
    "    ax[1,1].plot(mean, label = PFN_LIST[i])\n",
    "    ax[1,1].fill_between(mean.index.get_level_values('n_dims'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    best = regression_df[regression_df[PFN_LIST[i]+'_rank'] == 0]\n",
    "    noise_x = np.random.normal(0, 1.5, best.shape[0])\n",
    "    noise_y = np.random.normal(0, 1.5, best.shape[0])\n",
    "    ax[2,1].scatter(best['n_training_data']+noise_x, best['n_dims']+noise_y, s=3, label = PFN_LIST[i])\n",
    "\n",
    "# BASELINES\n",
    "cocabo_baseline = pd.read_csv('evaluation_data/regression_results_'+PFN_LIST[0]+'.csv')\n",
    "cocabo_baseline = cocabo_baseline[cocabo_baseline['model_name'] != 'PFN']\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "print(PFN_LIST)\n",
    "print('Average Ranks', avg_ranks)\n",
    "print('Win Proportion', proportion_wins)\n",
    "\n",
    "    \n",
    "ax[0,0].legend()\n",
    "ax[1,0].legend()\n",
    "ax[2,0].legend()\n",
    "ax[0,1].legend()\n",
    "ax[2,1].legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "del regression_df_list\n",
    "del PFN_LIST[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067df8c-5a5c-4afd-9bd0-8129eb88d358",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb52d7b-054d-40f0-9a2b-3a71a6df45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = 'overlap'\n",
    "\n",
    "divergence_df_list = []\n",
    "i = 0\n",
    "for index, pfn_no in enumerate(PFN_LIST):\n",
    "    print(index)\n",
    "    try:\n",
    "        dat_frame = pd.read_csv('bodi_evaluation_data/divergence_results_'+pfn_no+'.csv')\n",
    "        if (dat_frame['task_name']=='zakharov').sum() > 0:\n",
    "            divergence_df_list += [dat_frame]\n",
    "            divergence_df_list[i] = divergence_df_list[i][divergence_df_list[i]['model_name'] == 'PFN']\n",
    "            #divergence_df_list[i] = divergence_df_list[i][divergence_df_list[i]['task_name'] == 'ackley']\n",
    "            divergence_df_list[i]['PFN_number'] = pfn_no\n",
    "            divergence_df_list[i]['overlap'] = -divergence_df_list[i]['overlap']\n",
    "            i += 1\n",
    "        else:\n",
    "            print('BAD')\n",
    "    except:\n",
    "        print('CORRUPT')\n",
    "\n",
    "del dat_frame\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 12))\n",
    "ax[0,0].set_title('Overlap vs Amount of Training Data')\n",
    "ax[0,0].set_xlabel('Number of Training Points')\n",
    "ax[0,0].set_ylabel('Overlap')\n",
    "ax[1,0].set_title('Overlap vs Number of Dimensions')\n",
    "ax[1,0].set_xlabel('Number of Dimensions')\n",
    "ax[1,0].set_ylabel('Overlap')\n",
    "ax[2,0].set_title('Histogram of Divergence')\n",
    "ax[2,0].set_xlabel('Overlap')\n",
    "ax[0,1].set_title('Ranks')\n",
    "ax[0,1].set_xlabel('Number of Training Points')\n",
    "ax[0,1].set_ylabel('Rank')\n",
    "ax[1,1].set_title('Ranks')\n",
    "ax[1,1].set_xlabel('Number of Dimensions')\n",
    "ax[1,1].set_ylabel('Rank')\n",
    "ax[2,1].set_title('Best PFN with respect to Overlap')\n",
    "ax[2,1].set_xlabel('Number of Training Points')\n",
    "ax[2,1].set_ylabel('Number of Dimensions')\n",
    "\n",
    "mean_overlaps = np.zeros(len(PFN_LIST))\n",
    "\n",
    "for i, divergence_df in enumerate(divergence_df_list):\n",
    "    mean_overlaps[i] = divergence_df['overlap'].mean()\n",
    "    mean = divergence_df.groupby('n_training_data')[div].mean()\n",
    "    median = divergence_df.groupby('n_training_data')[div].median()\n",
    "    ub = divergence_df.groupby('n_training_data')[div].apply(bootstrap_ub)\n",
    "    lb = divergence_df.groupby('n_training_data')[div].apply(bootstrap_lb)\n",
    "    ax[0,0].plot(-mean, label = PFN_LIST[i])\n",
    "    ax[0,0].fill_between(mean.index.get_level_values('n_training_data'),\n",
    "                           -lb,\n",
    "                           -ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    divergence_df['n_dims'] = divergence_df['num_dims'] + divergence_df['cat_dims']\n",
    "    mean = divergence_df.groupby('n_dims')[div].mean()\n",
    "    median = divergence_df.groupby('n_dims')[div].median()\n",
    "    ub = divergence_df.groupby('n_dims')[div].apply(bootstrap_ub)\n",
    "    lb = divergence_df.groupby('n_dims')[div].apply(bootstrap_lb)\n",
    "    ax[1,0].plot(-mean, label = PFN_LIST[i])\n",
    "    ax[1,0].fill_between(mean.index.get_level_values('n_dims'),\n",
    "                           -lb,\n",
    "                           -ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    #divergence_df = divergence_df[divergence_df['n_training_data'] == 100]\n",
    "\n",
    "    #ax[2,0].hist(np.log(divergence_df[div]), alpha=0.3, bins=100, label = PFN_LIST[i])\n",
    "    ax[2,0].hist(-divergence_df[div], alpha=0.3, bins=100, label = PFN_LIST[i])\n",
    "\n",
    "# now we make ranking plot, using the raw loss calculations\n",
    "divergence_df = divergence_df_list[0]\n",
    "losses = np.array([df['overlap'] for df in divergence_df_list]).T\n",
    "ranks = np.argsort(losses, axis=1)\n",
    "ranks = np.argsort(ranks)\n",
    "\n",
    "avg_ranks = np.zeros(len(PFN_LIST))\n",
    "proportion_wins = np.zeros(len(PFN_LIST))\n",
    "\n",
    "for i in range(ranks.shape[1]):\n",
    "    divergence_df[PFN_LIST[i]+'_rank'] = ranks[:, i]\n",
    "    avg_ranks[i] = divergence_df[PFN_LIST[i]+'_rank'].mean()\n",
    "    proportion_wins[i] = (divergence_df[PFN_LIST[i]+'_rank'] == 0).mean()\n",
    "    mean = divergence_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].mean()\n",
    "    ub = divergence_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].apply(bootstrap_ub)\n",
    "    lb = divergence_df.groupby('n_training_data')[PFN_LIST[i]+'_rank'].apply(bootstrap_lb)\n",
    "    ax[0,1].plot(mean, label = PFN_LIST[i])\n",
    "    ax[0,1].fill_between(mean.index.get_level_values('n_training_data'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    mean = divergence_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].mean()\n",
    "    ub = divergence_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].apply(bootstrap_ub)\n",
    "    lb = divergence_df.groupby('n_dims')[PFN_LIST[i]+'_rank'].apply(bootstrap_lb)\n",
    "    ax[1,1].plot(mean, label = PFN_LIST[i])\n",
    "    ax[1,1].fill_between(mean.index.get_level_values('n_dims'),\n",
    "                           lb,\n",
    "                           ub,\n",
    "                           alpha=0.5)\n",
    "\n",
    "    best = divergence_df[divergence_df[PFN_LIST[i]+'_rank'] == 0]\n",
    "    noise_x = np.random.normal(0, 1.5, best.shape[0])\n",
    "    noise_y = np.random.normal(0, 1.5, best.shape[0])\n",
    "    ax[2,1].scatter(best['n_training_data']+noise_x, best['n_dims']+noise_y, s=3, label = PFN_LIST[i])\n",
    "\n",
    "print(PFN_LIST)\n",
    "print('Average Overlap', -mean_overlaps)\n",
    "print('Average Ranks', avg_ranks)\n",
    "print('Win Proportion', proportion_wins)\n",
    "\n",
    "    \n",
    "ax[0,0].legend()\n",
    "ax[1,0].legend()\n",
    "ax[2,0].legend()\n",
    "ax[0,1].legend()\n",
    "ax[2,1].legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "#del divergence_df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4118f-a7c1-4257-9400-f14c4b1eb879",
   "metadata": {},
   "source": [
    "# BO Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303f839-f7d1-426a-88ea-d6c35e32fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BO_df_list = []\n",
    "\n",
    "for i, pfn_no in enumerate(PFN_LIST):\n",
    "    BO_df_list += [pd.read_csv('casmo_evaluation_data/BO_results_pfn_'+pfn_no+'.csv')]\n",
    "    BO_df_list[i]['PFN_number'] = pfn_no\n",
    "    BO_df_list[i].reset_index(drop=True)\n",
    "\n",
    "cocabo_baseline = pd.read_csv('evaluation_data/BO_results_cocabo_baseline.csv')\n",
    "cocabo_baseline['PFN_number'] = 'CoCaBO'\n",
    "cocabo_baseline = cocabo_baseline.reset_index(drop=True)\n",
    "cocabo_baseline['optimizer_name'] = 'CoCaBO_pfnAcqFunc'\n",
    "cocabo_baseline_2 = cocabo_baseline.copy(deep=True)\n",
    "cocabo_baseline_2['optimizer_name'] = 'CoCaBO_mcboAcqFunc'\n",
    "cocabo_baseline = pd.concat([cocabo_baseline, cocabo_baseline_2], axis=0, ignore_index=True)\n",
    "BO_df_list += [cocabo_baseline]\n",
    "\n",
    "cocabo_baseline = pd.read_csv('evaluation_data/BO_results_casmo_baseline.csv')\n",
    "cocabo_baseline['PFN_number'] = 'Casmopolitan'\n",
    "cocabo_baseline = cocabo_baseline.reset_index(drop=True)\n",
    "cocabo_baseline['optimizer_name'] = 'Casmo_pfnAcqFunc'\n",
    "cocabo_baseline_2 = cocabo_baseline.copy(deep=True)\n",
    "cocabo_baseline_2['optimizer_name'] = 'Casmo_mcboAcqFunc'\n",
    "cocabo_baseline = pd.concat([cocabo_baseline, cocabo_baseline_2], axis=0, ignore_index=True)\n",
    "BO_df_list += [cocabo_baseline]\n",
    "\n",
    "random_baseline = pd.read_csv('evaluation_data/BO_results_random_baseline.csv')\n",
    "random_baseline['PFN_number'] = 'Random'\n",
    "random_baseline = random_baseline.reset_index(drop=True)\n",
    "random_baseline['optimizer_name'] = 'Random_pfnAcqFunc'\n",
    "random_baseline_2 = random_baseline.copy(deep=True)\n",
    "random_baseline_2['optimizer_name'] = 'Random_mcboAcqFunc'\n",
    "random_baseline = pd.concat([random_baseline, random_baseline_2], axis=0, ignore_index=True)\n",
    "BO_df_list += [random_baseline]\n",
    "\n",
    "if 'CoCaBO' not in PFN_LIST:\n",
    "    PFN_LIST += ['CoCaBO']\n",
    "if 'Casmo' not in PFN_LIST:\n",
    "    PFN_LIST += ['Casmo']\n",
    "if 'Random' not in PFN_LIST:\n",
    "    PFN_LIST += ['Random']\n",
    "\n",
    "results_full = pd.concat(BO_df_list, axis=0, ignore_index=False)\n",
    "\n",
    "results_full['task_number'] = pd.factorize(results_full['task_name'])[0]\n",
    "\n",
    "results = results_full[results_full['optimizer_name'].str.contains('pfnAcqFunc')]\n",
    "\n",
    "def rescale(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "results['best_y_scaled'] = results.groupby('task_name')['best_y'].transform(rescale)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(8, 12))\n",
    "\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    print('HERE', optimizer_name)\n",
    "    filtered_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    mean = filtered_df.groupby('nth_guess')['best_y_scaled'].mean()\n",
    "    median = filtered_df.groupby('nth_guess')['best_y_scaled'].median()\n",
    "    ub = filtered_df.groupby('nth_guess')['best_y_scaled'].apply(bootstrap_ub)\n",
    "    lb = filtered_df.groupby('nth_guess')['best_y_scaled'].apply(bootstrap_lb)\n",
    "    ax[0,0].plot(mean, label = PFN_LIST[i])\n",
    "    ax[0,0].fill_between(mean.index.get_level_values('nth_guess'),\n",
    "                       lb,\n",
    "                       ub,\n",
    "                       alpha=0.1)\n",
    "\n",
    "  \n",
    "\n",
    "ax[0,0].set_ylabel('best_y_scaled, averaged across all runs')\n",
    "ax[0,0].set_xlabel('iteration')\n",
    "ax[0,0].set_title('Optimizer Performance, PFN Acq Func')\n",
    "ax[0,0].legend()\n",
    "\n",
    "\n",
    "#now lets do a rank plot!\n",
    "BO_df = BO_df_list[0]\n",
    "best_ys = np.array([df['best_y'] for df in BO_df_list]).T\n",
    "ranks = np.argsort(best_ys, axis=1)\n",
    "ranks = np.argsort(ranks, axis=1)\n",
    "ranks = ranks.T.flatten()\n",
    "results_full['rank'] = ranks\n",
    "\n",
    "results = results_full[results_full['optimizer_name'].str.contains('pfnAcqFunc')]\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    rank_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    print('mean rank for ', optimizer_name, rank_df['rank'].mean())\n",
    "    mean = rank_df.groupby('nth_guess')['rank'].mean()\n",
    "    median = rank_df.groupby('nth_guess')['rank'].median()\n",
    "    ub = rank_df.groupby('nth_guess')['rank'].apply(bootstrap_ub)\n",
    "    lb = rank_df.groupby('nth_guess')['rank'].apply(bootstrap_lb)\n",
    "    ax[1,0].plot(mean)\n",
    "    ax[1,0].fill_between(mean.index.get_level_values('nth_guess'),\n",
    "                       lb,\n",
    "                       ub,\n",
    "                       alpha=0.1)\n",
    "\n",
    "ax[1,0].set_title('Ranking Plot')\n",
    "ax[1,0].set_ylabel('Average Rank Across All Setups')\n",
    "ax[1,0].set_xlabel('Iteration')\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    rank_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    print(optimizer_name+' win proportion: ', (rank_df['rank'] == 0).mean())\n",
    "    rank_df = rank_df[rank_df['rank'] == 0]\n",
    "\n",
    "    noise_x = np.random.normal(0, 0.3, rank_df.shape[0])\n",
    "    noise_y = np.random.normal(0, 0.3, rank_df.shape[0])\n",
    "\n",
    "    ax[2,0].scatter(rank_df['nth_guess']+noise_x, rank_df['task_number']+noise_y, s=1, label=optimizer_name)\n",
    "\n",
    "ax[2,0].set_ylabel('task number')\n",
    "ax[2,0].set_xlabel('iteration')\n",
    "ax[2,0].legend()\n",
    "\n",
    "\n",
    "#Now we do mcbo acq func!\n",
    "results = results_full[results_full['optimizer_name'].str.contains('mcboAcqFunc')]\n",
    "\n",
    "results['best_y_scaled'] = results.groupby('task_name')['best_y'].transform(rescale)\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    filtered_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    mean = filtered_df.groupby('nth_guess')['best_y_scaled'].mean()\n",
    "    median = filtered_df.groupby('nth_guess')['best_y_scaled'].median()\n",
    "    ub = filtered_df.groupby('nth_guess')['best_y_scaled'].apply(bootstrap_ub)\n",
    "    lb = filtered_df.groupby('nth_guess')['best_y_scaled'].apply(bootstrap_lb)\n",
    "    ax[0,1].plot(mean, label = PFN_LIST[i])\n",
    "    ax[0,1].fill_between(mean.index.get_level_values('nth_guess'),\n",
    "                       lb,\n",
    "                       ub,\n",
    "                       alpha=0.1)\n",
    "\n",
    "  \n",
    "\n",
    "ax[0,1].set_ylabel('best_y_scaled, averaged across all runs')\n",
    "ax[0,1].set_xlabel('iteration')\n",
    "ax[0,1].set_title('Optimizer Performance, MCBO Acq Func')\n",
    "ax[0,1].legend()\n",
    "\n",
    "\n",
    "#now lets do a rank plot!\n",
    "BO_df = BO_df_list[0]\n",
    "best_ys = np.array([df['best_y'] for df in BO_df_list]).T\n",
    "ranks = np.argsort(best_ys, axis=1)\n",
    "ranks = np.argsort(ranks, axis=1)\n",
    "ranks = ranks.T.flatten()\n",
    "results_full['rank'] = ranks\n",
    "\n",
    "results = results_full[results_full['optimizer_name'].str.contains('mcboAcqFunc')]\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    rank_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    print('mean rank for ', optimizer_name, rank_df['rank'].mean())\n",
    "    mean = rank_df.groupby('nth_guess')['rank'].mean()\n",
    "    median = rank_df.groupby('nth_guess')['rank'].median()\n",
    "    ub = rank_df.groupby('nth_guess')['rank'].apply(bootstrap_ub)\n",
    "    lb = rank_df.groupby('nth_guess')['rank'].apply(bootstrap_lb)\n",
    "    ax[1,1].plot(mean)\n",
    "    ax[1,1].fill_between(mean.index.get_level_values('nth_guess'),\n",
    "                       lb,\n",
    "                       ub,\n",
    "                       alpha=0.1)\n",
    "\n",
    "ax[1,1].set_title('Ranking Plot')\n",
    "ax[1,1].set_ylabel('Average Rank Across All Setups')\n",
    "ax[1,1].set_xlabel('Iteration')\n",
    "\n",
    "for i, optimizer_name in enumerate(results['optimizer_name'].unique()):\n",
    "    rank_df = results[results['optimizer_name'] == optimizer_name]\n",
    "    print(optimizer_name+' win proportion: ', (rank_df['rank'] == 0).mean())\n",
    "    rank_df = rank_df[rank_df['rank'] == 0]\n",
    "\n",
    "    noise_x = np.random.normal(0, 0.3, rank_df.shape[0])\n",
    "    noise_y = np.random.normal(0, 0.3, rank_df.shape[0])\n",
    "\n",
    "    ax[2,1].scatter(rank_df['nth_guess']+noise_x, rank_df['task_number']+noise_y, s=1, label=optimizer_name)\n",
    "\n",
    "ax[2,1].set_ylabel('task number')\n",
    "ax[2,1].set_xlabel('iteration')\n",
    "ax[2,1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "del PFN_LIST[-1]\n",
    "del PFN_LIST[-1]\n",
    "del PFN_LIST[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10113c-b167-4f3b-ac4a-77ec6eb2c4f8",
   "metadata": {},
   "source": [
    "# Direct Comparisons\n",
    "\n",
    "I now plot actual posterior distributions for a simple task to compare the behavior of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7ec26-79cb-4072-a08d-e6b935e96fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILENAME = 'trained_models/pfn_bodi_23.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652e908-f450-421d-b098-26f052caec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_kws = dict(variable_type=['num', 'nominal'],\n",
    "                    num_dims=[1, 1],\n",
    "                    lb=-1,\n",
    "                    ub=2,\n",
    "                    num_categories=[2, 2])\n",
    "\n",
    "task = task_factory(task_name=\"ackley\", **task_kws)\n",
    "\n",
    "search_space = task.get_search_space()\n",
    "\n",
    "n_init =1\n",
    "cocabo = BO_ALGOS['Casmopolitan'].build_bo(search_space=search_space, n_init=n_init, device=torch.device(\"cpu\"))\n",
    "optimizer_kwargs = {\n",
    "        'pfn_file': MODEL_FILENAME,\n",
    "        'acq_func': 'pi',\n",
    "        'acq_func_optim': 'mab',\n",
    "        #'device': 'cpu',\n",
    "        'fast':True\n",
    "    }\n",
    "\n",
    "mvpfn = MVPFNOptimizer(search_space=search_space,\n",
    "                       **optimizer_kwargs)\n",
    "\n",
    "def divergence(mu_cocabo, var_cocabo, mu_pfn, var_pfn):\n",
    "    div = torch.log(var_pfn / var_cocabo) + (var_cocabo + (mu_cocabo - mu_pfn) ** 2) / (2 * var_pfn) - 0.5\n",
    "    return div.mean().item()\n",
    "\n",
    "for i in [2, 4, 10, 20, 50, 100, 1000]:\n",
    "    print(i)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    mvpfn.restart()\n",
    "\n",
    "    # PFN    \n",
    "    X_pd = search_space.sample(i)\n",
    "    x = search_space.transform(X_pd).to(torch.float32)\n",
    "    y = task(X_pd)\n",
    "    test_x = torch.vstack([torch.linspace(0, 1, 100).repeat(2), torch.zeros(200)]).T.to(torch.float32)\n",
    "    test_x[100:, 1] = 1\n",
    "    \n",
    "\n",
    "    #plot the ground truth\n",
    "    ground_truth = task(search_space.inverse_transform(test_x))\n",
    "    ax[0].plot(test_x[:100,0].detach(), ground_truth[:100], c='black')\n",
    "    ax[0].plot(test_x[100:,0].detach(), ground_truth[100:], c='black')\n",
    "    \n",
    "    mvpfn.observe(X_pd, y)\n",
    "    \n",
    "    logits = mvpfn.model_pfn.pfn(x, mvpfn.model_pfn.y_to_fit_y(torch.from_numpy(y).to(torch.float32)), test_x.to(torch.float32))\n",
    "    mean = mvpfn.model_pfn.pfn.criterion.mean(logits)\n",
    "    var = mvpfn.model_pfn.pfn.criterion.variance(logits)\n",
    "    lower_pfn = mvpfn.model_pfn.pfn.criterion.icdf(logits, 0.025).flatten().detach()\n",
    "    upper_pfn = mvpfn.model_pfn.pfn.criterion.icdf(logits, 0.975).flatten().detach()\n",
    "    \n",
    "    mean = mvpfn.model_pfn.fit_y_to_y(mean)\n",
    "    lower_pfn = mvpfn.model_pfn.fit_y_to_y(lower_pfn)\n",
    "    upper_pfn = mvpfn.model_pfn.fit_y_to_y(upper_pfn)\n",
    "    \n",
    "    ax[0].plot(test_x[:100,0].detach(), mean[:100].detach())\n",
    "    ax[0].plot(test_x[100:,0].detach(), mean[100:].detach())\n",
    "    ax[0].fill_between(test_x[:100,0].detach(),\n",
    "                       lower_pfn[:100],\n",
    "                       upper_pfn[:100],\n",
    "                       alpha=0.5)\n",
    "    ax[0].fill_between(test_x[100:,0].detach(),\n",
    "                       lower_pfn[100:],\n",
    "                       upper_pfn[100:],\n",
    "                       alpha=0.5)\n",
    "\n",
    "    ax[0].scatter(x[:,0], y, c=x[:,1])\n",
    "\n",
    "    ax[0].set_title('PFN')\n",
    "\n",
    "    # COCABO\n",
    "    cocabo.restart()\n",
    "    cocabo = BO_ALGOS['Casmopolitan'].build_bo(search_space=search_space, n_init=n_init, device=torch.device(\"cpu\"))\n",
    "    _ = cocabo.model.fit(x, torch.from_numpy(y))\n",
    "    mean_cocabo, variance_cocabo = cocabo.model.predict(test_x)\n",
    "    lower_cocabo = (mean_cocabo - 1.96 * torch.sqrt(variance_cocabo)).detach().flatten()\n",
    "    upper_cocabo = (mean_cocabo + 1.96 * torch.sqrt(variance_cocabo)).detach().flatten()\n",
    "\n",
    "    ax[1].plot(test_x[:100, 0].detach(), mean_cocabo[:100].detach().flatten())\n",
    "    ax[1].plot(test_x[100:, 0].detach(), mean_cocabo[100:].detach().flatten())\n",
    "    ax[1].fill_between(test_x[:100, 0].detach(),\n",
    "                       lower_cocabo[:100],\n",
    "                       upper_cocabo[:100],\n",
    "                       alpha=0.5)\n",
    "    ax[1].fill_between(test_x[100:, 0].detach(),\n",
    "                       lower_cocabo[100:],\n",
    "                       upper_cocabo[100:],\n",
    "                       alpha=0.5)\n",
    "\n",
    "    ax[1].plot(test_x[:100,0].detach(), ground_truth[:100], c='black')\n",
    "    ax[1].plot(test_x[100:,0].detach(), ground_truth[100:], c='black')\n",
    "    ax[1].scatter(x[:,0], y, c=x[:,1])\n",
    "    ax[1].set_title('Casmopolitan')\n",
    "\n",
    "    # now we calculate the divergence\n",
    "    print(divergence(mean_cocabo, variance_cocabo, mean, var))\n",
    "    print(logits.shape)\n",
    "    # print('here', cocabo_logits_overlap(mean_cocabo, variance_cocabo, logits, mvpfn.model_pfn).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
